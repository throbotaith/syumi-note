# syumi-note
勉強ノートですので正確とは限りません．途中の物もいくつかあります．
## 分野別のNotebook一覧

### 強化学習

#### Reinforcement Learning : Theory and Algorithms（通称：Sutton本やRL Theorybook）
- 第1章（線形計画）：[RL_Theorybook_Chapter_1_LP.ipynb](RL_Theorybook_Chapter_1_LP.ipynb)
- 第1章：[RL_Theorybook_Chapter_1.ipynb](RL_Theorybook_Chapter_1.ipynb)
- 第2章：[RL_Theorybook_Chapter_2.ipynb](RL_Theorybook_Chapter_2.ipynb)
- 第3章：[RL_Theorybook_Chapter_3.ipynb](RL_Theorybook_Chapter_3.ipynb)
- 第4章：[RL_Theorybook_Chapter_4.ipynb](RL_Theorybook_Chapter_4.ipynb)
- 第11章：[RL_Theorybook_chapter_11.ipynb](RL_Theorybook_chapter_11.ipynb)
- 第12章：[RL_Theorybook_Chapter_12.ipynb](RL_Theorybook_Chapter_12.ipynb)
- 第14章（Conservative Policy Iteration）：[RL_Theorybook_Chapter_14_CPI.ipynb](RL_Theorybook_Chapter_14_CPI.ipynb)
- 第14章（Trust Region Policy Optimization(and PPO)）：[RL_Theorybook_Chapter_14_TRPO_PPO.ipynb](RL_Theorybook_Chapter_14_TRPO_PPO.ipynb)

#### その他のRL関連
- モデルフリーRLの復習：[RL_Model_Free.ipynb](RL_Model_Free.ipynb)
- sim2real：[RL_sim2real.ipynb](RL_sim2real.ipynb)
- 確率的方策勾配法：[RL_Stochastic_Policy_Gradient.ipynb](RL_Stochastic_Policy_Gradient.ipynb)
- 方策勾配法の理論：[RL_Theory of Policy Gradient.ipynb](RL_Theory of Policy Gradient.ipynb)
- 有限MDP理論（Puterman）：[MDP_Puterman_Infinite_Horizon.ipynb](MDP_Puterman_Infinite_Horizon.ipynb)
- Q学習の収束性証明：[RL_Q_Learning_proof_convergence.ipynb](RL_Q_Learning_proof_convergence.ipynb)
---

#### ロバストMDP（RMDP）
- RMDP理論論文の証明：[Paper_RMDP_thoery.ipynb](Paper_RMDP_thoery.ipynb)
- RMDPの基礎から方策勾配法まで（メモ）：[RMDP_foundations.ipynb](RMDP_foundations.ipynb)
- RDPにおける動的計画法のPythonコード：[Paper_RDP_implement.ipynb](Paper_RDP_implement.ipynb)
- RMDPにおける方策勾配法の大域的最適性証明：[RMDP_PG_global_optimality.ipynb](RMDP_PG_global_optimality.ipynb)
- モデル推定を行わないRMDP：[Paper_RMDP_wo_model_estimation.ipynb](Paper_RMDP_wo_model_estimation.ipynb)
---

#### バンディット問題
- ETCアルゴリズム：[Bandit_ETC.ipynb](Bandit_ETC.ipynb)


### CMDP（制約付きMDP）

- Altman本 第3章：[CMDP_Altman_Chapter_3.ipynb](CMDP_Altman_Chapter_3.ipynb)
- RCMDPのサブルーチン：[RCMDP_subrountine.ipynb](RCMDP_subrountine.ipynb)
---

### 分布ロバスト最適化（DRO）

- DRO理論本 第2章(導入、不確実性集合)：[DRO_Chapter_2_uncertainty_sets.ipynb](DRO_Chapter_2_uncertainty_sets.ipynb)
- DRO理論本 第3章(不確実性集合のトポロジー性質)：[DRO_Chapter_3_topology_of_uncertainty_sets.ipynb](DRO_Chapter_3_topology_of_uncertainty_sets.ipynb)
- DRO理論本 第4章(DROと双対問題)：[DRO_Chapter4_dual_theory_in_DRO.ipynb](DRO_Chapter4_dual_theory_in_DRO.ipynb)
- DRO理論本 第4章(最悪ケースDROと双対問題)：[DRO_Chapter_5_dual_theory_in_Risk_DRO.ipynb](DRO_Chapter_5_dual_theory_in_Risk_DRO.ipynb)

---

### 凸最適化と非線形最適化

#### First-order Methods in Optimization（Beck）
- 第4章（L-smooth & Strong Convex）：[Beck_gradient_Chapter_4_L-smooth_strong_convex.ipynb](Beck_gradient_Chapter_4_L-smooth_strong_convex.ipynb)

#### 非線形最適化の基礎(福島先生の本(*一般的な定理のまとめのみ))
- Chapter 1 + 可視化：[Non_Linear_optimization_chapter1_and_visualization.ipynb](Non_Linear_optimization_chapter1_and_visualization.ipynb)
- Chapter 2_part1(超平面、分離超平面、支持超平面、凸集合、陰関数定理など)：[Non_Linear_optimization_chapter2_part1.ipynb](Non_Linear_optimization_chapter2_part1.ipynb)
- Chapter 2_part2(凸関数、共役関数、劣勾配など)：[Non_Linear_optimization_chapter2_part2.ipynb](Non_Linear_optimization_chapter2_part2.ipynb)
- Chapter 3(最適性条件)：[Non_Linear_optimization_chapter3.ipynb](Non_Linear_optimization_chapter3.ipynb)
---

### 機械学習のための数理解析
- 確率不等式大全:[Math_Probability_Inequalities.ipynb](Math_Probability_Inequalities.ipynb)
- 一様収束と汎化解析(途中)：[Math_Uniform_Convergence.ipynb](Math_Uniform_Convergence.ipynb)



### 論文読み
- シミュレーション補題に関する考察：[Paper_Simulation_Lemma.ipynb](Paper_Simulation_Lemma.ipynb)
- Simplex法によるMDP解法：[Paper_Simplex_MDP.ipynb](Paper_Simplex_MDP.ipynb)
- モーメンタムはSGDを改善させる：[Paper_Momentum_improves_SGD.ipynb](Paper_Momentum_improves_SGD.ipynb)
- 価値関数ポリトープ：[Paper_Geometory_of_Value_Function.ipynb](Paper_Geometory_of_Value_Function.ipynb)
- ロバスト価値関数ポリトープ[Paper_Geometory_of_Robust_Value_Function.ipynb](Paper_Geometory_of_Robust_Value_Function.ipynb)

### その他


- 拡散モデルの理論：[Theory_of_diffusion_model.ipynb](Theory_of_diffusion_model.ipynb)
- RL用ユーティリティ：[RL_utils.ipynb](RL_utils.ipynb)



## 日付順のNotebook一覧

1. 11/20：Beck本第3章、劣勾配の基礎
2. 11/21：Beck本第3章、劣勾配の計算からKKT条件まで
3. 11/22：Beck本第4章、L-smooth前半
4. 12/05：RMDPのPIアルゴリズムの実装
5. 12/25：On the Theory of Policy Gradient Methods,直接パラメータ化のSample Complexity導出
6. 01/98：Occupancy Measureを解析したいの章
7. 01/27：RMDPの基礎1
8. 02/06　基礎2
9. 02/09：非凸ミニマックス問題
10. 02/11：モデルフリー強化学習備忘録
11. 02/16：sim2real paper
12. 03/03：SPGにおけるN-PG-IGTの証明(1)
13. 03/04：SPGにおけるN-PG-IGTの証明(完)
14. 03/05：SPGとN-PG-IGTを組み合わたアルゴリズム素案の作成
15. 03/08：分布ロバスト最適化の不確実性集合についてのまとめ(DRO2章)
16. 03/09：アルゴリズム素案の証明スケッチ
17. 03/11：手法の疑問をまとめた。
18. 03/16：DRO3章1
19. 03/18：DRO3章2
20. 03/19：強化学習理論本14章,保守的方策反復
21. 03/22：凸解析の基礎
22. 03/26：凸解析の基礎2
23. 03/27：確率不等式１．マルコフの不等式
24. 03/28：サポート型不確実性集合
25. 03/29：$\phi$-ダイバージェンス不確実集合
26. 03/30：凸解析の基礎3(凸関数の性質)
27. 03/31：不確実性集合のトポロジー的性質
28. 04/01：分布ロバスト最適化における双対理論(DRO4章)1
29. 04/02：パフォーマンス差とシミュレーション差
30. 04/03：PAC学習
31. 04/04：強化学習理論本14章TRPO
32. 04/05：モーメンタムはSGDを改善させる1
33. 04/06：モーメンタムはSGDを改善させる完、分布ロバスト最適化における双対理論(DRO4章)2
34. 04/07：確率不等式(サブガウシアン、ベルンシュタインの不等式)
35. 04/08：RMDPにおける方策勾配法の大域的最適性証明
36. 04/09：sim2real paper2
37. 04/10：価値関数のポリトープ1
38. 04/11：価値関数のポリトープ完
39. 04/12：分布ロバスト最適化における双対理論(DRO4章)3
40. 04/13：Q学習の収束性
41. 04/14：凸解析の基礎3(KKT条件)
42. 04/15：モデル推定を行わないRMDP1
43. 04/16：ロバスト価値関数のポリトープ1
44. 04/17：一様収束と汎化1
45. 04/18：強化学習理論本第1章　[RL_Theorybook_Chapter_1.ipynb](RL_Theorybook_Chapter_1.ipynb)
46. 04/19：強化学習理論本第1章(途中)　[RL_Theorybook_Chapter_4.ipynb](RL_Theorybook_Chapter_4.ipynb)
47. 04/20：sim2real paper3
48. 04/21：ETCアルゴリズム[Bandit_ETC.ipynb](Bandit_ETC.ipynb)
49. 04/22：凸関数の基礎4(双対問題)
50. 04/23：モデル推定を行わないRMDP2[Paper_RMDP_wo_model_estimation.ipynb](Paper_RMDP_wo_model_estimation.ipynb)
51. 04/24：最悪ケースリスク問題における双対理論(DRO5章)1[DRO_Chapter_5_dual_theory_in_Risk_DRO.ipynb](DRO_Chapter_5_dual_theory_in_Risk_DRO.ipynb)
