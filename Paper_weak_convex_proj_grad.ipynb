{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9fbf65e",
   "metadata": {},
   "source": [
    "# 弱凸関数の確率的モデルベース最小化\n",
    "\n",
    "## 最適化問題\n",
    "この論文では，最初に正則化された最適化問題を定式化しています．\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\min _{x \\in \\mathbb{R}^{d}} \\varphi(x)=f(x)+r(x) \\quad \\text { where } \\quad f(x)=\\mathbb{E}_{\\xi \\sim P}[f(x, \\xi)] \\tag{SO}\n",
    "\\end{equation*}\n",
    "$$\n",
    "ここで，各変数は以下の通りです．\n",
    "*$x$： 意思決定規則をパラメータ化したベクトル ($\\in \\mathbb{R}^d$)\n",
    "*$P$：未知の確率分布\n",
    "*$\\xi$：$P$に従う確率変数\n",
    "*$f(x, \\xi)$：損失関数\n",
    "*$r(x)$：正則化項\n",
    "\n",
    "### 近接勾配法\n",
    "この問題を解く方法として，近接勾配法という方法があり，この研究では推されています．詳しくは確率的最適化のページを見てください．これは射影勾配法の一般化であり，以下のような処理の繰り返しで目的関数の最小化を目指します．\n",
    "**アルゴリズム**\n",
    "$$\n",
    "\\left\\{\\begin{array}{l}\n",
    "\\text { Sample } \\xi_{t} \\sim P  \\tag{SG}\\\\\n",
    "\\text { Set } x_{t+1}=\\operatorname{prox}_{\\alpha_{t} r}\\left(x_{t}-\\alpha_{t} \\nabla_{x} f\\left(x_{t}, \\xi_{t}\\right)\\right)\n",
    "\\end{array}\\right\\},\n",
    "$$\n",
    "\n",
    "ここで，$\\alpha_{t}>0$はステップサイズ，$\\operatorname{prox}_{\\alpha r}(\\cdot)$配下に定義するような近接写像です．\n",
    "$$\n",
    "\\operatorname{prox}_{\\alpha r}(x):=\\underset{y}{\\operatorname{argmin}}\\left\\{r(y)+\\frac{1}{2 \\alpha}\\|y-x\\|^{2}\\right\\}\n",
    "$$\n",
    "これを，非平滑かつ，凸な関数に対しても応用した場合，劣勾配という概念を用いて最適化することが可能です．\n",
    "\n",
    "### 弱凸性とモロー包絡\n",
    "RMDPの目的関数をはじめとしたよく使われる関数クラスとして，弱凸関数があります．ここで，関数$g: \\mathbb{R}^d \\rightarrow \\mathbb{R}$が$\\rho$-**弱凸 (weakly convex)** であるとは，\n",
    "$$\n",
    "x \\mapsto g(x) + \\frac{\\rho}{2}\\|x\\|^2\n",
    "$$が凸関数である場合を言います．\n",
    "\n",
    "\n",
    "![](https://cdn.mathpix.com/cropped/2025_05_13_caf8d02d67f5adbae3e8g-04.jpg?height=492&width=1156&top_left_y=318&top_left_x=281)\n",
    "\n",
    "## 確率的射影劣勾配法\n",
    "各点で真の劣勾配を計算しない場合を考えます．例えば期待値の計算が困難な場合が考えられます．そこで，確率的な劣勾配推定値$G(x, \\xi)$がサンプル可能である場合を考えます．これを用いてパラメータ更新を行いますが，仮定として$\\mathbb{E}_\\xi[G(x, \\xi)] \\in \\partial \\varphi(x)$を置きます．つまり，劣勾配推定値は劣微分のどれかに属している．つまり真の劣勾配のどれかと一致しているというものです．\n",
    "\n",
    "### アルゴリズム\n",
    "劣勾配が推定値に変わっただけです．\n",
    "\n",
    "入力:$x_{0} \\in \\operatorname{dom} r$，$\\{\\alpha_t\\}_{t \\geq 0} \\subset \\mathbb{R}_{+}$， 反復回数$T$\n",
    "ステップ$t=0, \\ldots, T$:\n",
    "   $\\left\\{\\begin{array}{l}\\xi_{t} \\sim P\\\\ x_{t+1}=\\operatorname{prox}_{\\alpha_{t} r}\\left(x_{t}-\\alpha_{t} G\\left(x_{t}, \\xi_{t}\\right)\\right)\\end{array}\\right\\}$\n",
    "$t^{*} \\in\\{0, \\ldots, T\\}$を，$\\mathbb{P}(t^{*}=t)=\\frac{\\alpha_{t}}{\\sum_{i=0}^{T} \\alpha_{i}}$に従ってサンプリングする．\n",
    "出力:$x_{t^{*}}$\n",
    "\n",
    "### 確率的劣勾配オラクル(仮定A)\n",
    "このオラクルは，勾配推定値を返す役割を持っています．ここで，確率空間$(\\Omega, \\mathcal{F}, P)$を固定し，$\\mathbb{R}^{d}$をボレル$\\sigma$-代数とします．オラクルは，以下の３つの仮定を満たす必要があります．\n",
    "\n",
    "(A1) 独立同分布でsること:$\\xi_{1}, \\xi_{2}, \\ldots \\sim P$ということです．\n",
    "(A2)$\\operatorname{dom} r$を含む開集合$U$と，すべての$x \\in U$に対して$\\mathbb{E}_{\\xi}[G(x, \\xi)] \\in \\partial f(x)$を満たす可測写像$G: U \\times \\Omega \\rightarrow \\mathbb{R}^{d}$が存在します．要はオラクルは真の劣勾配のどれかをサンプルするということです．\n",
    "(A3) すべての$x \\in \\operatorname{dom} r$に対して不等式$\\mathbb{E}_{\\xi}\\left[\\|G(x, \\xi)\\|^{2}\\right] \\leq L^{2}$を満たす実数$L \\geq 0$が存在します．オラクルによる劣勾配推定値のノルムは有界です．\n",
    "\n",
    "### 確率的射影列勾配法による勾配の0への収束(定理3.1)\n",
    "\n",
    "近接確率的劣勾配法において，正則化項$r$が閉凸集合$\\mathcal{X}$の指示関数である場合を考えます．つまり，確率的射影劣勾配法を考えます．\n",
    "\n",
    "仮定A (A1, A2, A3) が成りつ場合，\n",
    "\n",
    "任意の$\\bar{\\rho} > \\rho$に対して，モロー包絡線関数の期待値に関する1ステップでの不等式が以下のように成り立ちます．\n",
    "$$\n",
    "\\mathbb{E}[\\varphi_{1/\\bar{\\rho}}(x_{t+1})] \\leq \\mathbb{E}[\\varphi_{1/\\bar{\\rho}}(x_t)] - \\frac{\\alpha_t(\\bar{\\rho}-\\rho)}{\\bar{\\rho}}\\mathbb{E}[\\|\\nabla \\varphi_{1/\\bar{\\rho}}(x_t)\\|^2] + \\frac{\\bar{\\rho}\\alpha_t^2 L^2}{2}\n",
    "$$\n",
    "\n",
    "アルゴリズムの出力$x_{t^*}$におけるモロー包絡線関数の勾配の二乗ノルム期待値に関する上界が成り立ちます．\n",
    "       $$\\mathbb{E}[\\|\\nabla \\varphi_{1/\\bar{\\rho}}(x_{t^*})\\|^2] \\leq \\frac{\\bar{\\rho}}{\\bar{\\rho}-\\rho} \\cdot \\frac{(\\varphi_{1/\\bar{\\rho}}(x_0)-\\min \\varphi)+\\frac{\\bar{\\rho} L^2}{2} \\sum \\alpha_t^2}{\\sum \\alpha_t}$$\n",
    "        $\\alpha_t = \\frac{\\gamma}{\\sqrt{T+1}}$とした場合の勾配二乗ノルム期待値に関する上界は以下のようになります．\n",
    "       $$\\mathbb{E}[\\|\\nabla \\varphi_{1/2\\rho}(x_{t^*})\\|^2] \\leq 2 \\cdot \\frac{(\\varphi_{1/2\\rho}(x_0)-\\min \\varphi)+\\rho L^2 \\gamma^2}{\\gamma \\sqrt{T+1}}$$\n",
    "### 定理3.1の証明\n",
    "\n",
    "**1.$\\mathbb{E}_t[\\varphi_{1/\\bar{\\rho}}(x_{t+1})]$の上界を導出する\n",
    "\n",
    "モロー包絡線の定義は，$\\varphi_\\lambda(x) = \\min_y \\{\\varphi(y) + \\frac{1}{2\\lambda}\\|y-x\\|^2\\}$です．この最小化の最適解は$y = \\operatorname{prox}_{\\lambda \\varphi}(x)$です．定義から，以下が成り立ちます．\n",
    "\n",
    "$$\\varphi_{1/\\bar{\\rho}}(x_{t+1}) \\leq \\varphi(\\hat{x}_t) + \\frac{1}{2(1/\\bar{\\rho})}\\|\\hat{x}_t - x_{t+1}\\|^2 = \\varphi(\\hat{x}_t) + \\frac{\\bar{\\rho}}{2}\\|\\hat{x}_t - x_{t+1}\\|^2$$\n",
    "\n",
    "この不等式の両辺に対して$\\mathbb{E}_t[\\cdot]$をとります．$\\hat{x}_t = \\operatorname{prox}_{\\varphi/\\bar{\\rho}}(x_t)$は$x_t$に依存しますが，$\\xi_t$には依存しないため，$\\varphi(\\hat{x}_t)$は定数となります．\n",
    "\n",
    "$$\\mathbb{E}_t[\\varphi_{1/\\bar{\\rho}}(x_{t+1})] \\leq \\mathbb{E}_t\\left[\\varphi(\\hat{x}_t) + \\frac{\\bar{\\rho}}{2}\\|\\hat{x}_t - x_{t+1}\\|^2\\right] = \\varphi(\\hat{x}_t) + \\frac{\\bar{\\rho}}{2}\\mathbb{E}_t[\\|\\hat{x}_t - x_{t+1}\\|^2] \\quad \\text{(3.6)}$$\n",
    "\n",
    "次に，$\\mathbb{E}_t[\\|\\hat{x}_t - x_{t+1}\\|^2]$の項を詳しくみていきます．アルゴリズムの更新式は$x_{t+1} = \\operatorname{prox}_{\\alpha_t r}(x_t - \\alpha_t G(x_t, \\xi_t))$です．定理3.1の文脈では，$r$は閉凸集合$\\mathcal{X}$の指示関数なので，$\\operatorname{prox}_{\\alpha_t r}(\\cdot)$は射影$\\operatorname{proj}_{\\mathcal{X}}(\\cdot)$に等しくなります．よって，$x_{t+1} = \\operatorname{proj}_{\\mathcal{X}}(x_t - \\alpha_t G(x_t, \\xi_t))$です．\n",
    "\n",
    "また，モロー包絡線の近接点$\\hat{x}_t = \\operatorname{prox}_{\\varphi/\\bar{\\rho}}(x_t)$の定義を考えます．$\\varphi = f + r$であり，$r$が指示関数$I_\\mathcal{X}$なので，$\\varphi = f + I_\\mathcal{X}$です．近接写像の定義から$\\hat{x}_t = \\operatorname{prox}_{(f+I_\\mathcal{X})/\\bar{\\rho}}(x_t)$です．これは，関数$y \\mapsto f(y) + I_\\mathcal{X}(y) + \\frac{\\bar{\\rho}}{2}\\|y - x_t\\|^2$の最小化点であり，制約$y \\in \\mathcal{X}$の下で関数$y \\mapsto f(y) + \\frac{\\bar{\\rho}}{2}\\|y - x_t\\|^2$を最小化する点と等価です．つまり，$\\hat{x}_t \\in \\mathcal{X}$です．\n",
    "\n",
    "閉凸集合への射影の性質として，集合内の点$\\hat{x}_t$に対しては$\\operatorname{proj}_{\\mathcal{X}}(\\hat{x}_t) = \\hat{x}_t$となります．\n",
    "\n",
    "さらに，$\\operatorname{proj}_{\\mathcal{X}}(\\cdot)$は非拡大です．つまり，任意の2点$a, b$に対して$\\|\\operatorname{proj}_{\\mathcal{X}}(a) - \\operatorname{proj}_{\\mathcal{X}}(b)\\| \\le \\|a - b\\|$が成り立ちます．先ほどの話と，非拡大の性質を利用すると，\n",
    "\n",
    "$$\\|\\hat{x}_t - x_{t+1}\\|^2 = \\|\\operatorname{proj}_{\\mathcal{X}}(\\hat{x}_t) - \\operatorname{proj}_{\\mathcal{X}}(x_t - \\alpha_t G(x_t, \\xi_t))\\|^2 \\leq \\|\\hat{x}_t - (x_t - \\alpha_t G(x_t, \\xi_t))\\|^2 \\quad \\text{(式 3.7)}$$\n",
    "となります．次に，右辺のノルムの二乗を展開します．備忘録($\\|A - B\\|^2 = \\|A\\|^2 - 2\\langle A, B \\rangle + \\|B\\|^2$)\n",
    "\n",
    "$$\\|\\hat{x}_t - (x_t - \\alpha_t G(x_t, \\xi_t))\\|^2 = \\|\\hat{x}_t - x_t + \\alpha_t G(x_t, \\xi_t)\\|^2$$\n",
    "$$= \\|\\hat{x}_t - x_t\\|^2 + 2\\alpha_t \\langle \\hat{x}_t - x_t, G(x_t, \\xi_t) \\rangle + \\alpha_t^2 \\|G(x_t, \\xi_t)\\|^2$$\n",
    "\n",
    "次にこの式に$\\mathbb{E}_t[\\cdot]$をとります．\n",
    "$x_t, \\hat{x}_t, \\alpha_t$は$\\xi_t$に依存しないため，期待値から外せます．\n",
    "\n",
    "$$\\mathbb{E}_t[\\|\\hat{x}_t - x_{t+1}\\|^2] \\leq \\|\\hat{x}_t - x_t\\|^2 + 2\\alpha_t \\mathbb{E}_t[\\langle \\hat{x}_t - x_t, G(x_t, \\xi_t) \\rangle] + \\alpha_t^2 \\mathbb{E}_t[\\|G(x_t, \\xi_t)\\|^2]$$\n",
    "\n",
    "仮定A2より$\\mathbb{E}_t[G(x_t, \\xi_t)] = v_t \\in \\partial f(x_t)$です．また，仮定A3より$\\mathbb{E}_t[\\|G(x_t, \\xi_t)\\|^2] \\le L^2$です．\n",
    "\n",
    "$$\\mathbb{E}_t[\\|\\hat{x}_t - x_{t+1}\\|^2] \\leq \\|\\hat{x}_t - x_t\\|^2 + 2\\alpha_t \\langle \\hat{x}_t - x_t, v_t \\rangle + \\alpha_t^2 L^2$$\n",
    "\n",
    "これを最初の不等式$\\mathbb{E}_t[\\varphi_{1/\\bar{\\rho}}(x_{t+1})] \\leq \\varphi(\\hat{x}_t) + \\frac{\\bar{\\rho}}{2}\\mathbb{E}_t[\\|\\hat{x}_t - x_{t+1}\\|^2]$に代入します．\n",
    "\n",
    "$$\\mathbb{E}_t[\\varphi_{1/\\bar{\\rho}}(x_{t+1})] \\leq \\varphi(\\hat{x}_t) + \\frac{\\bar{\\rho}}{2}\\left( \\|\\hat{x}_t - x_t\\|^2 + 2\\alpha_t \\langle \\hat{x}_t - x_t, v_t \\rangle + \\alpha_t^2 L^2 \\right)$$\n",
    "$$= \\varphi(\\hat{x}_t) + \\frac{\\bar{\\rho}}{2}\\|\\hat{x}_t - x_t\\|^2 + \\bar{\\rho}\\alpha_t \\langle \\hat{x}_t - x_t, v_t \\rangle + \\frac{\\bar{\\rho}\\alpha_t^2 L^2}{2}$$\n",
    "\n",
    "ここで，モロー包絡線の定義$\\varphi_{1/\\bar{\\rho}}(x_t) = \\varphi(\\hat{x}_t) + \\frac{\\bar{\\rho}}{2}\\|x_t - \\hat{x}_t\\|^2$を利用して最初の2項をまとめます．\n",
    "\n",
    "$$\\mathbb{E}_t[\\varphi_{1/\\bar{\\rho}}(x_{t+1})] \\leq \\varphi_{1/\\bar{\\rho}}(x_t) + \\bar{\\rho}\\alpha_t \\langle \\hat{x}_t - x_t, v_t \\rangle + \\frac{\\bar{\\rho}\\alpha_t^2 L^2}{2}$$\n",
    "\n",
    "次に，$\\|\\nabla \\varphi_{1/\\bar{\\rho}}(x_t)\\|^2$の項を考えます．補題2.2より$\\|\\nabla \\varphi_{1/\\bar{\\rho}}(x_t)\\| = \\bar{\\rho}\\|x_t - \\hat{x}_t\\|$なので，$\\|\\nabla \\varphi_{1/\\bar{\\rho}}(x_t)\\|^2 = \\bar{\\rho}^2\\|x_t - \\hat{x}_t\\|^2$です．したがって，$\\|\\hat{x}_t - x_t\\|^2 = \\frac{1}{\\bar{\\rho}^2}\\|\\nabla \\varphi_{1/\\bar{\\rho}}(x_t)\\|^2$です．\n",
    "\n",
    "ここで，弱凸性（パラメータ$\\rho$）の性質と，劣勾配$v_t \\in \\partial f(x_t)$を利用します．弱凸性の劣勾配不等式 (2.5) は，$f(y) \\ge f(x) + \\langle v, y-x \\rangle - \\frac{\\rho}{2}\\|y-x\\|^2$for$v \\in \\partial f(x)$です．\n",
    "これに$x = x_t, y = \\hat{x}_t, v = v_t$を代入します．\n",
    "\n",
    "$$f(\\hat{x}_t) \\ge f(x_t) + \\langle v_t, \\hat{x}_t - x_t \\rangle - \\frac{\\rho}{2}\\|\\hat{x}_t - x_t\\|^2$$\n",
    "\n",
    "この不等式を変形して，評価したい項$\\langle \\hat{x}_t - x_t, v_t \\rangle$を上から抑えます．\n",
    "\n",
    "$$\\langle \\hat{x}_t - x_t, v_t \\rangle \\leq f(\\hat{x}_t) - f(x_t) + \\frac{\\rho}{2}\\|\\hat{x}_t - x_t\\|^2$$\n",
    "\n",
    "これを先の評価式に代入します．\n",
    "\n",
    "$$\\mathbb{E}_t[\\varphi_{1/\\bar{\\rho}}(x_{t+1})] \\leq \\varphi_{1/\\bar{\\rho}}(x_t) + \\bar{\\rho}\\alpha_t \\left( f(\\hat{x}_t) - f(x_t) + \\frac{\\rho}{2}\\|\\hat{x}_t - x_t\\|^2 \\right) + \\frac{\\bar{\\rho}\\alpha_t^2 L^2}{2} \\quad \\text{(式 3.8)}$$\n",
    "\n",
    "これが証明中の式 (3.8) です．次に，カッコ内の項$\\left( f(\\hat{x}_t) - f(x_t) + \\frac{\\rho}{2}\\|\\hat{x}_t - x_t\\|^2 \\right)$をさらに評価します．\n",
    "\n",
    "関数$x \\mapsto f(x) + \\frac{\\bar{\\rho}}{2}\\|x - x_t\\|^2$を考えます．$f$は$\\rho$-弱凸なので，$f(x) + \\frac{\\rho}{2}\\|x\\|^2$は凸です．これに凸関数$\\frac{\\bar{\\rho}-\\rho}{2}\\|x - x_t\\|^2$を加えた関数$f(x) + \\frac{\\rho}{2}\\|x\\|^2 + \\frac{\\bar{\\rho}-\\rho}{2}\\|x - x_t\\|^2 = f(x) + \\frac{\\rho}{2}\\|x\\|^2 + \\frac{\\bar{\\rho}-\\rho}{2}(\\|x\\|^2 - 2\\langle x, x_t \\rangle + \\|x_t\\|^2)$は凸です．したがって，$f(x) + \\frac{\\bar{\\rho}}{2}\\|x\\|^2 + \\frac{\\bar{\\rho}-\\rho}{2}\\|x_t\\|^2 - (\\bar{\\rho}-\\rho)\\langle x, x_t \\rangle$は凸であり，これは$f(x) + \\frac{\\bar{\\rho}}{2}\\|x\\|^2 - (\\bar{\\rho}-\\rho)\\langle x, x_t \\rangle + \\text{const}$という形になります．\n",
    "\n",
    "より直接的に，$f(x) + \\frac{\\rho}{2}\\|x\\|^2$が凸であり，$\\frac{\\bar{\\rho}}{2}\\|x - x_t\\|^2 = \\frac{\\bar{\\rho}}{2}\\|x\\|^2 - \\bar{\\rho}\\langle x, x_t \\rangle + \\frac{\\bar{\\rho}}{2}\\|x_t\\|^2$であることから，$f(x) + \\frac{\\bar{\\rho}}{2}\\|x - x_t\\|^2 = \\left(f(x) + \\frac{\\rho}{2}\\|x\\|^2\\right) + \\frac{\\bar{\\rho}-\\rho}{2}\\|x\\|^2 - \\bar{\\rho}\\langle x, x_t \\rangle + \\frac{\\bar{\\rho}}{2}\\|x_t\\|^2$となります．もし$\\bar{\\rho} \\ge \\rho$ならば$\\frac{\\bar{\\rho}-\\rho}{2}\\|x\\|^2$は凸関数なので，全体の関数は凸関数と凸関数の和になり凸関数となります．\n",
    "\n",
    "しかし，証明ではより強い強凸性を利用しています．関数$g(x) = f(x) + \\frac{\\bar{\\rho}}{2}\\|x - x_t\\|^2$を考えます．$f$が$\\rho$-弱凸であることから，$f(x) + \\frac{\\rho}{2}\\|x\\|^2$は凸です．$g(x) + \\frac{\\rho-\\bar{\\rho}}{2}\\|x\\|^2 = f(x) + \\frac{\\rho}{2}\\|x\\|^2 - \\bar{\\rho}\\langle x, x_t \\rangle + \\frac{\\bar{\\rho}}{2}\\|x_t\\|^2$は凸なので，$g(x)$は$(\\bar{\\rho}-\\rho)$-弱凸です．\n",
    "\n",
    "実は，点$\\hat{x}_t = \\operatorname{prox}_{\\varphi/\\bar{\\rho}}(x_t)$は，関数$y \\mapsto \\varphi(y) + \\frac{\\bar{\\rho}}{2}\\|y - x_t\\|^2$の最小化点です．$r$が指示関数なので，これは$y \\mapsto f(y) + \\frac{\\bar{\\rho}}{2}\\|y - x_t\\|^2$の$\\mathcal{X}$上での最小化点です．\n",
    "\n",
    "証明では，この関数$x \\mapsto f(x)+\\frac{\\bar{\\rho}}{2}\\|x-x_{t}\\|^{2}$がパラメータ$\\bar{\\rho}-\\rho$で強凸であると述べています．\n",
    "これは，$f$が$\\rho$-弱凸である（すなわち$f(x) + \\frac{\\rho}{2}\\|x\\|^2$が凸）ことから，$f(x) + \\frac{\\bar{\\rho}}{2}\\|x\\|^2 = (f(x) + \\frac{\\rho}{2}\\|x\\|^2) + \\frac{\\bar{\\rho}-\\rho}{2}\\|x\\|^2$は，凸関数と強凸関数（$\\bar{\\rho} > \\rho$の場合）の和なので強凸となり，パラメータは$\\bar{\\rho}-\\rho$です．したがって，関数$x \\mapsto f(x)+\\frac{\\bar{\\rho}}{2}\\|x-x_{t}\\|^{2}$も強凸であり，その強凸性パラメータは$\\bar{\\rho}-\\rho$です．\n",
    "\n",
    "強凸関数$h(x)$の最小化点$x^*$における劣勾配$v \\in \\partial h(x^*)$が0を含むこと，および強凸性の定義$h(y) \\ge h(x) + \\langle v, y-x \\rangle + \\frac{\\mu}{2}\\|y-x\\|^2$($v \\in \\partial h(x)$) より，$h(y) \\ge h(x^*) + \\frac{\\mu}{2}\\|y-x^*\\|^2$が成り立ちます．\n",
    "ここで，$h(x) = f(x) + \\frac{\\bar{\\rho}}{2}\\|x - x_t\\|^2$とし，その最小化点$x^* = \\hat{x}_t$とします．強凸性パラメータは$\\mu = \\bar{\\rho}-\\rho$です．任意の点$x$に対して以下が成り立ちます．\n",
    "\n",
    "$$f(x) + \\frac{\\bar{\\rho}}{2}\\|x - x_t\\|^2 \\ge f(\\hat{x}_t) + \\frac{\\bar{\\rho}}{2}\\|\\hat{x}_t - x_t\\|^2 + \\frac{\\bar{\\rho}-\\rho}{2}\\|x - \\hat{x}_t\\|^2$$\n",
    "\n",
    "これに$x = x_t$を代入します．\n",
    "\n",
    "$$f(x_t) + \\frac{\\bar{\\rho}}{2}\\|x_t - x_t\\|^2 \\ge f(\\hat{x}_t) + \\frac{\\bar{\\rho}}{2}\\|\\hat{x}_t - x_t\\|^2 + \\frac{\\bar{\\rho}-\\rho}{2}\\|x_t - \\hat{x}_t\\|^2$$\n",
    "$$f(x_t) \\ge f(\\hat{x}_t) + \\frac{\\bar{\\rho}}{2}\\|\\hat{x}_t - x_t\\|^2 + \\frac{\\bar{\\rho}-\\rho}{2}\\|x_t - \\hat{x}_t\\|^2$$\n",
    "\n",
    "この不等式を変形して，証明中のカッコ内の項$f(\\hat{x}_t) - f(x_t) + \\frac{\\rho}{2}\\|x_t - \\hat{x}_t\\|^2$を上から抑えます．\n",
    "\n",
    "$$f(x_t) - f(\\hat{x}_t) \\ge \\frac{\\bar{\\rho}}{2}\\|\\hat{x}_t - x_t\\|^2 + \\frac{\\bar{\\rho}-\\rho}{2}\\|x_t - \\hat{x}_t\\|^2 = \\frac{2\\bar{\\rho}-\\rho}{2}\\|x_t - \\hat{x}_t\\|^2$$\n",
    "$$f(\\hat{x}_t) - f(x_t) \\le -\\frac{2\\bar{\\rho}-\\rho}{2}\\|x_t - \\hat{x}_t\\|^2$$\n",
    "\n",
    "このままでは式 (3.8) のカッコ内の形になりません．もう一度，証明中で使われている式変形をよく見ます．証明では，**$\\langle \\hat{x}_t - x_t, v_t \\rangle$を評価する**のではなく，**$f(x_t) - f(\\hat{x}_t) - \\frac{\\rho}{2}\\|x_t - \\hat{x}_t\\|^2$を評価**しています．この項は，上で導出した強凸性の不等式から直接下界が得られます．\n",
    "\n",
    "$$f(x_t) - f(\\hat{x}_t) - \\frac{\\rho}{2}\\|x_t - \\hat{x}_t\\|^2 \\ge (\\bar{\\rho}-\\rho)\\|x_t - \\hat{x}_t\\|^2$$\n",
    "\n",
    "これを式 (3.8) のカッコ内の項$\\left( f(\\hat{x}_t) - f(x_t) + \\frac{\\rho}{2}\\|x_t - \\hat{x}_t\\|^2 \\right)$に代入するために，符号を反転します．\n",
    "\n",
    "$$-\\left(f(x_t) - f(\\hat{x}_t) - \\frac{\\rho}{2}\\|x_t - \\hat{x}_t\\|^2\\right) \\leq -(\\bar{\\rho}-\\rho)\\|x_t - \\hat{x}_t\\|^2$$\n",
    "$$\\left(f(\\hat{x}_t) - f(x_t) + \\frac{\\rho}{2}\\|x_t - \\hat{x}_t\\|^2\\right) \\leq -(\\bar{\\rho}-\\rho)\\|x_t - \\hat{x}_t\\|^2$$\n",
    "\n",
    "これを式 (3.8) に代入します．\n",
    "\n",
    "$$\\mathbb{E}_t[\\varphi_{1/\\bar{\\rho}}(x_{t+1})] \\leq \\varphi_{1/\\bar{\\rho}}(x_t) + \\bar{\\rho}\\alpha_t \\left( -(\\bar{\\rho}-\\rho)\\|x_t - \\hat{x}_t\\|^2 \\right) + \\frac{\\bar{\\rho}\\alpha_t^2 L^2}{2}$$\n",
    "$$= \\varphi_{1/\\bar{\\rho}}(x_t) - \\bar{\\rho}\\alpha_t (\\bar{\\rho}-\\rho)\\|x_t - \\hat{x}_t\\|^2 + \\frac{\\bar{\\rho}\\alpha_t^2 L^2}{2}$$\n",
    "\n",
    "最後に，モロー包絡線の勾配と$\\|x_t - \\hat{x}_t\\|$の関係$\\|\\nabla \\varphi_{1/\\bar{\\rho}}(x_t)\\| = \\bar{\\rho}\\|x_t - \\hat{x}_t\\|$(補題2.2) を使って，$\\|x_t - \\hat{x}_t\\|^2$を$\\|\\nabla \\varphi_{1/\\bar{\\rho}}(x_t)\\|^2$に置き換えます．\n",
    "\n",
    "$$\\|x_t - \\hat{x}_t\\|^2 = \\frac{1}{\\bar{\\rho}^2}\\|\\nabla \\varphi_{1/\\bar{\\rho}}(x_t)\\|^2$$\n",
    "\n",
    "$$\\mathbb{E}_t[\\varphi_{1/\\bar{\\rho}}(x_{t+1})] \\leq \\varphi_{1/\\bar{\\rho}}(x_t) - \\bar{\\rho}\\alpha_t (\\bar{\\rho}-\\rho) \\frac{1}{\\bar{\\rho}^2}\\|\\nabla \\varphi_{1/\\bar{\\rho}}(x_t)\\|^2 + \\frac{\\bar{\\rho}\\alpha_t^2 L^2}{2}$$\n",
    "$$= \\varphi_{1/\\bar{\\rho}}(x_t) - \\frac{\\alpha_t(\\bar{\\rho}-\\rho)}{\\bar{\\rho}}\\|\\nabla \\varphi_{1/\\bar{\\rho}}(x_t)\\|^2 + \\frac{\\bar{\\rho}\\alpha_t^2 L^2}{2}$$\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
