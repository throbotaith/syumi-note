{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMDPの実装\n",
    "\n",
    "Sample Complexity of Robust Reinforcement Learning with a Generative Modelのアルゴリズム1を実装してみました。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最適行動価値関数 Q:\n",
      "[[5.11584115 5.01856317]\n",
      " [5.40760664 5.52351439]]\n",
      "最適方策 π:\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "S = 2  # 状態数\n",
    "A = 2  # 行動数\n",
    "gamma = 0.9  # 割引率\n",
    "K = 1000  # イテレーション回数\n",
    "epsilon = 1  # KL上限\n",
    "n = 1000  # Uncertainty setを作る際の遷移確率サンプルのサンプル数\n",
    "\n",
    "P = np.zeros((S, A, S))  # 真の遷移確率\n",
    "r = np.random.rand(S, A)  # 報酬\n",
    "\n",
    "for s in range(S):\n",
    "    for a in range(A):\n",
    "        P[s, a] = np.random.rand(S)\n",
    "        P[s, a] /= np.sum(P[s, a])\n",
    "\n",
    "def generative_model(P, s, a):\n",
    "    return np.random.choice(S, p=P[s, a])\n",
    "\n",
    "def compute_emprical_P(n, P, P_hat):\n",
    "    for s in range(S):\n",
    "        for a in range(A):\n",
    "            for _ in range(n):\n",
    "                s_next = generative_model(P, s, a)\n",
    "                P_hat[s, a, s_next] += 1\n",
    "    for s in range(S):\n",
    "        for a in range(A):\n",
    "            if np.sum(P_hat[s, a]) > 0:\n",
    "                P_hat[s, a] /= np.sum(P_hat[s, a])\n",
    "    return P_hat\n",
    "\n",
    "def KL_divergence(P, Q):\n",
    "    return np.sum(P * np.log(np.clip(P / Q, 1e-10, None)))\n",
    "\n",
    "def compute_uncertainty_set(P_hat, epsilon):\n",
    "    uncertainty_set = []\n",
    "    num_samples = 10 \n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        candidate = np.zeros((S, A, S))\n",
    "        for s in range(S):\n",
    "            for a in range(A):\n",
    "                candidate[s, a] = np.random.rand(S)\n",
    "                candidate[s, a] /= np.sum(candidate[s, a])\n",
    "        if np.all([KL_divergence(P_hat[s, a], candidate[s, a]) <= epsilon for s in range(S) for a in range(A)]):\n",
    "            uncertainty_set.append(candidate)\n",
    "    return uncertainty_set\n",
    "\n",
    "def sigma_uncertainty(P_set, s, a, V_k):\n",
    "    # 不確実性集合に基づく最小期待値を計算\n",
    "    return np.min([np.sum(P[s, a, :] * V_k) for P in P_set])\n",
    "\n",
    "# 推定遷移確率とUncertainty setの計算\n",
    "P_hat = np.zeros_like(P)  \n",
    "P_hat = compute_emprical_P(n, P, P_hat)\n",
    "uncertainty_set = compute_uncertainty_set(P_hat, epsilon)\n",
    "\n",
    "Q = np.zeros((S, A))  \n",
    "\n",
    "for k in range(K):\n",
    "    V = np.max(Q, axis=1)  \n",
    "    Q_new = np.zeros_like(Q)  \n",
    "\n",
    "    for s in range(S):\n",
    "        for a in range(A):\n",
    "            Q_new[s, a] = r[s, a] + gamma * sigma_uncertainty(uncertainty_set, s, a, V)\n",
    "\n",
    "    # 収束判定 (θ = 0.0001)\n",
    "    if np.max(np.abs(Q_new - Q)) < theta:\n",
    "        break\n",
    "\n",
    "    Q = Q_new  # Qを更新\n",
    "\n",
    "# 最適方策の計算\n",
    "pi = np.argmax(Q, axis=1)\n",
    "\n",
    "# 出力\n",
    "print(\"最適行動価値関数 Q:\")\n",
    "print(Q)\n",
    "print(\"最適方策 π:\")\n",
    "print(pi)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
