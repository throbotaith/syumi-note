{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1418190",
   "metadata": {},
   "source": [
    "## このノートについて\n",
    "このページでは，[Robust Markov Decision Processes without Model Estimation](https://arxiv.org/abs/2302.01248)の勉強ノートを書きます．\n",
    "\n",
    "\n",
    "## 準備\n",
    "本題に入る前に定義や仮定などを整理しましょう．\n",
    "### 記法\n",
    "*   $\\Delta(\\mathcal{X})$: 有限集合 $\\mathcal{X}$ 上の確率分布の集合\n",
    "*   $Q \\ll P$: 確率分布 $Q$ は $P$ に関して絶対連続\n",
    "*   $D_f(Q \\| P)$: $f$-ダイバージェンス\n",
    "*   $f^*(t)$: 関数 $f$ の凸共役\n",
    "*   $\\sigma(X)$: 確率変数 $X$ によって生成されるシグマ代数\n",
    "\n",
    "### 分布ロバスト最適化 (DRO)\n",
    "\n",
    "**制約付きDRO問題 (1)**: \n",
    "$$\n",
    "\\mathcal{R}_{c}\\left(P^{*}, V\\right):=\\inf _{P \\in \\Delta(\\mathcal{X}), D_{f}\\left(P \\| P^{*}\\right) \\leq \\rho} \\sum_{x \\in \\mathcal{X}} P(x) V(x)\n",
    "$$\n",
    "**制約付きDROの双対形式 (2)**\n",
    "$\\lambda, \\eta$ :双対変数，$f_{\\eta, \\lambda, V}^{\\dagger}(x)=f^{*}\\left(\\frac{\\eta-V(x)}{\\lambda}\\right)$\n",
    "$$\n",
    "\\sup _{\\lambda \\geq 0, \\eta \\in \\mathbb{R}}\\left[-\\lambda \\sum P^{*}(x) f_{\\eta, \\lambda, V}^{\\dagger}(x)-\\lambda \\rho+\\eta\\right]\n",
    "$$\n",
    "\n",
    "**ペナルティDRO問題(3)**: \n",
    "$$\n",
    "\\mathcal{R}_{p}\\left(P^{*}, V\\right):=\\inf _{P \\in \\Delta(\\mathcal{X})} \\sum_{x \\in \\mathcal{X}} P(x) V(x)+\\lambda D_{f}\\left(P \\| P^{*}\\right)\n",
    "$$\n",
    "**ペナルティDROの双対形式 (4)**\n",
    "$$\n",
    "\\sup _{\\eta \\in \\mathbb{R}}\\left[-\\lambda \\sum P^{*}(x) f_{\\eta, \\lambda, V}^{\\dagger}(x)+\\eta\\right]\n",
    "$$\n",
    " \n",
    "### ロバストマルコフ決定過程 (RMDP)\n",
    "\n",
    "**定義**\n",
    "* $\\left\\langle\\mathcal{S}, \\mathcal{A}, P^{*}, R, \\gamma\\right\\rangle$ (状態空間, 行動空間, 基準遷移関数, 報酬関数, 割引率)\n",
    "*   **($s, a$)-rectangular不確実性集合**: $\\mathcal{P}:=\\otimes_{s, a \\in \\mathcal{S} \\times \\mathcal{A}} \\mathcal{P}_{s, a}(\\rho)$\n",
    "*   **ロバスト価値関数 (制約付き)**:\n",
    "$$\n",
    "V_{\\text {rob }, \\mathrm{c}}^{\\pi}(s):=\\inf _{P \\in \\mathcal{P}} V_{P}^{\\pi}(s)\n",
    "$$\n",
    "*   **最適ロバスト価値関数 (制約付き)**:\n",
    "$$\n",
    "V_{\\text {rob,c }}^{*}:=\\max _{\\pi} V_{\\text {rob,c }}^{\\pi}\n",
    "$$\n",
    "*   **ロバストベルマン作用素 (制約付き)**:\n",
    "$$\n",
    "\\mathcal{T}_{\\text {rob }, \\mathrm{c}} V(s):=\\max _{a \\in \\mathcal{A}}\\left(R(s, a)+\\gamma \\inf _{P(\\cdot \\mid s, a) \\in \\mathcal{P}_{s, a}(\\rho)} \\sum_{s^{\\prime} \\in \\mathcal{S}} P\\left(s^{\\prime} \\mid s, a\\right) V\\left(s^{\\prime}\\right)\\right)\n",
    "$$\n",
    "*   **ロバストベルマン作用素の双対形式(6)**:\n",
    "$$\n",
    "\\mathcal{T}_{\\text {rob }, \\mathrm{c}} V(s):=\\max _{a \\in \\mathcal{A}}\\left(R(s, a)+\\gamma \\sup _{\\lambda \\geq 0, \\eta \\in \\mathbb{R}}\\left[-\\lambda rho+\\eta-\\lambda \\mathbb{E}_{P_{s, a}^{*}}\\left[f_{\\eta, \\lambda, V}^{\\dagger}\\left(s^{\\prime}\\right)\\right]\\right]\\right)\n",
    "$$\n",
    "\n",
    "*   **ペナルティロバスト価値関数(7):**\n",
    "$$\n",
    "V_{\\mathrm{rob}, \\mathrm{p}}^{\\pi}(s):=\\inf _{P \\in \\Delta\\left(\\mathcal{S})^{|\\mathcal{S}||\\mathcal{A}|}\\right.} \\mathbb{E}_{P, \\pi}\\left[\\sum_{t=0}^{\\infty} \\gamma^{t}\\left(R\\left(s_{t}, a_{t}\\right)+\\lambda \\gamma D_{f}\\left(P\\left(\\cdot \\mid s_{t}, a_{t}\\right) \\| P^{*}\\left(\\cdot \\mid s_{t}, a_{t}\\right)\\right)\\right) \\mid s_{0}=s\\right]\n",
    "$$\n",
    "\n",
    "*   **ペナルティロバストベルマン作用素(8):**\n",
    "$$\n",
    "\\mathcal{T}_{\\text {rob }, \\mathrm{p}} V(s):=\\max _{a \\in \\mathcal{A}}\\left(R(s, a)+\\gamma \\inf _{P(\\cdot \\mid s, a) \\in \\Delta(\\mathcal{S})}\\left[\\sum_{s^{\\prime} \\in \\mathcal{S}} P\\left(s^{\\prime} \\mid s, a\\right) V\\left(s^{\\prime}\\right)+\\lambda D_{f}\\left(P(\\cdot \\mid s, a) \\| P^{*}(\\cdot \\mid s, a)\\right)\\right]\\right)\n",
    "$$\n",
    "\n",
    "*   **ペナルティロバストベルマン行動作用素 :**\n",
    "$$\n",
    "\\mathcal{T}_{\\text {rob }, \\mathrm{p}} Q(s, a):=R(s, a)+\\gamma \\sup _{\\eta \\in \\mathbb{R}}\\left[-\\lambda \\mathbb{E}_{s^{\\prime} \\sim P_{s, a}^{*}} f^{*}\\left(\\frac{\\eta-\\max _{a^{\\prime}} Q\\left(s^{\\prime}, a^{\\prime}\\right)}{\\lambda}\\right)+\\eta\\right]\n",
    "$$\n",
    "\n",
    "*   **双対形式の目的関数:**\n",
    "\t* $f_{\\eta, \\lambda, V}^{\\dagger}\\left(s^{\\prime}\\right) = f^{*}\\left(\\frac{\\eta-V\\left(s^{\\prime}\\right)}{\\lambda}\\right)$，$V(s') = \\max_{a'} Q(s', a')$\n",
    "$$\n",
    "J^{(s, a)}(\\eta, V):=-\\lambda \\sum_{s^{\\prime} \\in \\mathcal{S}} P^{*}\\left(s^{\\prime} \\mid s, a\\right) f_{\\eta, \\lambda, V}^{\\dagger}\\left(s^{\\prime}\\right)+\\eta\n",
    "$$\n",
    "\n",
    "*   **双対目的関数の確率的評価 ($J_{t}^{(s, a)}\\left(\\eta, V ; s_{t}^{\\prime}(s, a)\\right)$):**\n",
    "$$\n",
    "J_{t}^{(s, a)}\\left(\\eta, V ; s_{t}^{\\prime}(s, a)\\right):=-\\lambda f_{\\eta, \\lambda, V}^{\\dagger}\\left(s_{t}^{\\prime}(s, a)\\right)+\\eta\n",
    "$$\n",
    "\n",
    "## 命題と定理\n",
    "### 命題\n",
    "#### 命題 3.1\n",
    "\n",
    "$\\mathcal{T}_{\\text {rob }, p}$ は価値関数の空間 $\\mathcal{V} = [0, 1/(1-\\gamma)]^{|\\mathcal{S}|}$ 上の $\\gamma$-縮小作用素である．したがって，一意な固定点 $V_{\\text {rob }, p}^{*}$ が存在し，それは最適ペナルティロバスト価値関数 $V_{r o b, p}^{*}=\\max _{\\pi} V_{r o b, p}^{\\pi}$ と一致する．\n",
    "* ペナルティロバストベルマン作用素を適用していくと，最適ペナルティロバスト価値関数は一つかつそれに収束します．\n",
    "\n",
    "### 定理\n",
    "#### 定理 3.1\n",
    " \n",
    " $f(\\cdot)$-ダイバージェンスを持つRMDPにおいて，\n",
    "1.  任意の制約パラメータ $\\rho > 0$ に対して，あるペナルティパラメータ $\\lambda > 0$ が存在し，与えられた初期分布 $\\mu \\in \\Delta(\\mathcal{S})$ に対して $V_{\\text {rob,c }}^{*}(\\mu)=V_{\\text {rob }, p}^{*}(\\mu)$ となる．\n",
    "2.  逆に，任意のペナルティパラメータ $\\lambda > 0$ に対して，ある制約パラメータ $\\rho > 0$ が存在し，$V_{\\text {rob }, p}^{*}(\\mu)=V_{\\text {rob,c}}^{*}(\\mu)$ となる．\n",
    "\n",
    "つまり，RMDPにおけるminmax(コスト最小化)とmaxmin(報酬最大化)は同値であるということが言えます．\n",
    "\n",
    "\n",
    "#### 定理 3.2\n",
    "\n",
    "Generative modelを用い，遷移確率を $n$ 個のサンプルで経験的に推定 $\\widehat{P}\\left(s^{\\prime} \\mid s, a\\right)=\\frac{1}{n} \\sum_{i=1}^{n} \\mathbf{1}\\left(X_{i}^{(s, a)}=s^{\\prime}\\right)$ する場合 ($X_{i}^{(s, a)} \\sim P^{*}(\\cdot \\mid s, a)$)$f(s)=(s-1)^{2}$ (カイ二乗ダイバージェンス不確実性集合) を選択すると，確率 $1-\\delta$ で以下が成り立つ：\n",
    "\n",
    "**大域的最適性**\n",
    "$$\n",
    "\\left\\|\\widehat{V}_{r o b, p}^{*}-V_{r o b, p}^{*}\\right\\|_{\\infty} \\leq \\widetilde{\\mathcal{O}}\\left(\\frac{\\max \\left\\{\\frac{1}{\\lambda(1-\\gamma)^{2}}, \\lambda\\right\\}}{(1-\\gamma) \\sqrt{n}}\\right)\n",
    "$$\n",
    "\n",
    "**サンプル複雑度 ($\\lambda=\\mathcal{O}(1-\\gamma)$ の場合)**\n",
    "$$\n",
    "\\widetilde{\\Omega}\\left(\\frac{|\\mathcal{S}||\\mathcal{A}| \\lambda^{2}}{\\varepsilon^{2}(1-\\gamma)^{3}}\\right)\n",
    "$$\n",
    "**サンプル複雑度 ($\\lambda=\\Omega(1-\\gamma)$ の場合)**\n",
    "$$\n",
    "\\widetilde{\\Omega}\\left(\\frac{|\\mathcal{S}||\\mathcal{A}|}{\\varepsilon^{2}(1-\\gamma)^{3}} \\min \\left\\{\\frac{1}{16}, \\frac{\\lambda \\gamma(1-\\gamma)}{2 \\gamma-1}\\right\\}\\right)\n",
    "$$\n",
    "#### 定理 3.2の証明:TODO\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
