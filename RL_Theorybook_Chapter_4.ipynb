{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b84cb4e",
   "metadata": {},
   "source": [
    "# Reinforcement Learning: Theory and Algorithms\n",
    "* 第3章における各定理，補題，系などをまとめます．証明は初見でもこれを参考にすれば導出できるように丁寧に記します．\n",
    "* 必要に応じて実装を行います．\n",
    "\n",
    "この章では，関数近似を使って動的計画法(DP)を解く方法を見ていきます．DPは最適性を持つので，解けたら嬉しいですよね．第3章では線形関数で上手くいく特別な場合を見ましたが，ここではもっと一般的な関数近似と，DPのVIとPIを組み合わせる方法を探します．\n",
    "\n",
    "本章では，以下のような手法を扱います．\n",
    "**Fitted Q-Iteration (FQI):** \n",
    "* 値反復っぽい計算をします．$Q$関数を関数クラス $\\mathcal{F}$ から回帰で見つける感じです．これは事前に集めたデータだけでできるのでオフラインRLの一つです．\n",
    "**Fitted Policy Iteration (FPI):** \n",
    "* 方策反復っぽいアプローチです．これは実際に試行錯誤してデータを集める（エピソード実行）必要があります．\n",
    "\n",
    "\n",
    "**この章での目標:**\n",
    "*   関数近似を使ったときに，平均的にどれくらいいい感じになるかの保証 (誤差評価) をゲットしたいわけです．\n",
    "\t*   そのために集中係数 (Concentration Coefficient)という，ちょっと強めの仮定を使います．これは，データがいろんな状況をちゃんとカバーしてるかの度合いを示すものです．\n",
    "\n",
    "## FQIとオフラインRL\n",
    "\n",
    "### 準備\n",
    "*   事前データ： $\\mathcal{D} = \\{(s_i, a_i, r_i, s'_i)\\}_{i=1}^n$ \n",
    "\t*   分布 $\\nu$ に従って $(s_i, a_i)$ が選ばれます．そこに$r_i$ ，$s'_i$ を集めたタプルの集合です．\n",
    "\t*   このデータだけを使って，最適方策$\\hat{\\pi}$ (つまり $V(\\hat{\\pi})$ が $V^\\star$ に近いポリシー) に近いものを求めたいわけです．\n",
    "*   関数クラス $\\mathcal{F}$: 値域は $[0, V_{\\max}]$ です．\n",
    "*   $\\|f\\|_{2, \\nu}^2 = \\mathbb{E}_{s, a \\sim \\nu} [f(s, a)^2]$ ：ノルム\n",
    "\n",
    "**仮定 4.1 (集中性):** \n",
    "データ収集に使われた $\\nu$ が，どんな$\\pi$で訪れる可能性のある $(s, a)$ も，ある程度ちゃんとカバーしてるという仮定です．\n",
    "* $\\pi$ で $(s, a)$ を訪れる占有測度 $d^\\pi(s, a)$ と $\\nu(s, a)$ の比が，定数 $C$ で抑えられてる ($d^\\pi(s, a) / \\nu(s, a) \\le C$) ということです．\n",
    "\n",
    "**仮定 4.2 (固有のベルマン誤差):** \n",
    "  $\\mathcal{T}f$ で関数を更新しても，$f \\in \\mathcal{F}$のどれかと$\\epsilon_{\\text{approx}, \\nu}$ の誤差でしかないという仮定です．\n",
    "$$\n",
    "\\epsilon_{\\text {approx }, \\nu} := \\max _{f \\in \\mathcal{F}} \\min _{f^{\\prime} \\in \\mathcal{F}}\\left\\|f^{\\prime}-\\mathcal{T} f\\right\\|_{2, \\nu}^2 \n",
    "$$\n",
    "## FQI アルゴリズム\n",
    "アルゴリズムは以下のようになっています．\n",
    "\n",
    "1.  最初に $f_0 \\in \\mathcal{F}$ (例えば全部ゼロとか) から始めます\n",
    "2.  $t=1, 2, \\dots, K$ っで，以下の計算を繰り返します\n",
    "    *    $f_{t-1}$ を使って，$y_i = r_i + \\gamma \\max_{a'} f_{t-1}(s'_i, a')$ をデータ $\\mathcal{D}$ の各サンプル $(s_i, a_i, r_i, s'_i)$ について計算します\n",
    "    *    $\\mathcal{F}$ の中で， $(s_i, a_i)$ に対して $f(s_i, a_i)$ が， $y_i$ に一番近くなるような関数 $f$ を以下のような式を用いて**回帰**で見つけます        \n",
    "$$ \n",
    "f_t \\in \\operatorname{argmin}_{f \\in \\mathcal{F}} \\sum_{i=1}^n ( f(s_i, a_i) - y_i )^2 \n",
    "$$\n",
    "つまり，\n",
    "$$\n",
    "\\quad f_t \\in \\operatorname{argmin}_{f \\in \\mathcal{F}} \\sum_{i=1}^n \\left( f(s_i, a_i) - (r_i + \\gamma \\max_{a'} f_{t-1}(s'_i, a')) \\right)^2 \n",
    "$$\n",
    "1. 最後に得られた $f_K$ を使って，$\\pi^K(s) = \\operatorname{argmax}_a f_K(s, a)$ を出力します\n",
    "\n",
    "**直感?**\n",
    "もし $\\mathcal{F}$ が完璧で，データもほぼ無限にあれば， $f_t$ は最適ベルマン作用素の適用 $\\mathcal{T} f_{t-1}$と同じになるわけです．つまり作用素の適用を無限大に繰り返していくと，$Q^\\star$ を求められそうです．\n",
    "\n",
    "\n",
    "## FQIの性能保証\n",
    "\n",
    "### FQIのサンプル複雑度(定理 4.3 )\n",
    "FQI を $K$ 回反復して得られた $\\pi^K$ は，$1-\\delta$ 以上で，以下の不等式を満たします．\n",
    "\n",
    "$$ V^{\\star}-V^{\\pi^K} \\leq \\underbrace{\\frac{1}{(1-\\gamma)^2} \\left( \\sqrt{\\frac{C \\cdot (\\text{なんか色々})}{n}} + \\sqrt{C \\cdot \\epsilon_{\\text{approx}, \\nu}} \\right)}_{\\text{データ数と関数近似能力による誤差}} + \\underbrace{\\frac{\\gamma^K V_{\\max}}{1-\\gamma}}_{\\text{反復回数による誤差}} $$\n",
    "* いい感じの関数クラス($\\epsilon_{\\text{approx}), \\nu}$小さい，集中性小さい(C$ 小)，データ多い ($n$ 大) ，反復数多い($K$ 大)と上界は下がります．\n",
    "\n",
    "### 定理4.3の証明\n",
    "\n",
    "補題4.4と補題4.5を用いて証明を行います．\n",
    "#### 補題4.4(誤差伝搬の制御)\n",
    "\n",
    "もし、FQI の各反復ステップ $t$ において、生成された $f_{t+1}$ と $\\mathcal{T} f_t$ との間の $L_{2, \\nu}$ ノルムの誤差が $\\left\\|f_{t+1}-\\mathcal{T} f_t\\right\\|_{2, \\nu} \\leq \\varepsilon$ で抑えられていると仮定します．このとき、以下のような不等式が成立します．\n",
    "$$\n",
    "V^{\\star} - V^{\\pi^k} \\leq \\frac{\\sqrt{C} \\varepsilon}{1-\\gamma} + \\frac{\\gamma^k V_{\\max }}{(1-\\gamma)^2}\n",
    "$$\n",
    "#### 補題4.4の証明\n",
    "Performance difference lemmaを用います．\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
