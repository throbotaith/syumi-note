{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reinforcement Learning: Theory and Algorithms\n",
    "\n",
    "* 第3章における各定理、補題、系などをまとめます。証明は初見でもこれを参考にすれば導出できるように丁寧に記します。\n",
    "* 必要に応じて実装を行います。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Bellman Completeness(LBC) \n",
    "\n",
    "* 状態数と行動数が大きい場合(可算あるいは非可算無限)場合にうまく動くアルゴリズムを考えます。\n",
    "* LBCはある条件であり、これを満たすと多項式的なサンプル複雑度で最適な方策を学習できます。\n",
    "* 本章では**有限-Horizon**MDPに焦点を当てます。\n",
    "\n",
    "\n",
    "#### 準備\n",
    "* 線形関数：$f(s, a) := \\theta^{\\top} \\phi(s, a)$\n",
    "* 特徴写像：$\\phi: \\mathcal{S} \\times \\mathcal{A} \\mapsto \\mathbb{R}^d$\n",
    "\n",
    "\n",
    "\n",
    "#### Linear Bellman Completeness\n",
    "\n",
    "特徴 $\\phi$ がLinear Bellman Completenessを満たすとは、任意の $\\theta \\in \\mathbb{R}^d$ および $(s, a, h) \\in \\mathcal{S} \\times \\mathcal{A} \\times[H]$ に対して、次を満たす $w \\in \\mathbb{R}^d$ が存在することをいいます。\n",
    "\n",
    "$$\n",
    "w^{\\top} \\phi(s, a) = r(s, a) + \\mathbb{E}_{s^{\\prime} \\sim P_h(s, a)} \\max_{a^{\\prime}} \\theta^{\\top} \\phi(s^{\\prime}, a^{\\prime}).\n",
    "$$\n",
    "\n",
    "$w$ は $\\theta$ に依存するため、上記の方程式で $w := \\mathcal{T}_h(\\theta)$ と表記します。\n",
    "\n",
    "* 線形関数にベルマン作用素を適用($w^{\\top} \\phi(s, a) = \\mathcal{T}_h(\\theta)\\phi(s, a)$)しても、適用結果が線形関数で表現できる(右辺)という条件です。つまり、線形関数にベルマン作用素を適用しても非線形関数とかにならないという条件です。\n",
    "* 線形であることのメリットとして、$Q_h^{\\star}(s, a) = (\\theta_h^{\\star})^{\\top} \\phi(s, a)$ を満たす $\\theta_h^{\\star}$ が存在することが挙げられます。つまりLBCを満たせば、最適価値関数は必ず存在するということです。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSVIアルゴリズム\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
