{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27c90ff9",
   "metadata": {},
   "source": [
    "# このページについて\n",
    "被覆数推定に関する勉強のまとめです．作成に当たっては，トン・ジャン先生の[機械学習のための数理解析](https://tongzhang-ml.org/)を大いに参考にさせていただきました．\n",
    "\n",
    "# パッキング数\n",
    "被覆数とは異なる手法です．ある距離が一定上になるような空間上の点を要素とするものです．\n",
    "\n",
    "**定義1 (パッキング数)**\n",
    "$(V, d)$ を距離 $d(\\cdot, \\cdot)$ を持つ擬距離空間とします．有限部分集合 $G(\\epsilon) \\subset G$ が $G$ の $\\epsilon$-パッキングであるとは、全ての $\\phi, \\phi' \\in G(\\epsilon)$ (ただし $\\phi \\neq \\phi'$) に対して $d(\\phi, \\phi') > \\epsilon$ が成り立つ場合をいういます．$G$ の $\\epsilon$-パッキング数 $M(\\epsilon, G, d)$ とは、$G$ の $\\epsilon$-パッキングの濃度の最大数です．\n",
    "\n",
    "* 疑似距離空間とは，異なる2点間の距離が0になることを許容する空間のことです．\n",
    "* εを選んで，そこからパッキング数を求めますが，そこで求められるような要素の最大個数を言います．εに限りなく近い距離閾値をもつものがおそらく最大であると思います．\n",
    "* εが大きいほどパッキング数は小さくなり，εが大きいほどパッキング数は大きくなります．\n",
    "* パッキング数は小さいほうがいいですが，小さすぎると考えられる空間の表現力が低くなるのであまり良いことではないようです．\n",
    "\n",
    "# パッキング数と被覆数\n",
    "**被覆数のおさらい**\n",
    "被覆数とは，$N(\\epsilon, G, d)$集合Gを半径εのボールで覆うために必要な最小のボールの数の個数を意味します．パッキング数とは似た指標ですが，少し異なります．\n",
    "\n",
    "これらに対しては以下の定理が成り立ちます．\n",
    "\n",
    "**定理2 (定理 5.2)**\n",
    "全ての $\\epsilon > 0$ に対して、次が成り立ちます．\n",
    "$$\n",
    "N(\\epsilon, G, d) \\le M(\\epsilon, G, d) \\le N(\\epsilon/2, G, d)\n",
    "$$\n",
    "* 被覆に必要な点の数はεパッキングの点の数以下となります．\n",
    "* εを半分にすると，被覆数はパッキング数よりも大きくなります．\n",
    "* これをみると，被覆数のほうがタイトな気がしますがパッキング数というかパッキングは疑似距離空間の部分空間なので疑似距離空間です．ですので理論解析においては結構有用な性質をもっていたりします．\n",
    "\n",
    "**定理2の証明**\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
