{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# このページについて\n",
    "このページでは、Distributionally Robust Optimization(https://arxiv.org/abs/2411.02549)の第1章から2章の勉強内容をまとめていこうと思います。\n",
    "\n",
    "\n",
    "## 分布ロバスト最適化とは\n",
    "最適化問題において、確実に既知であるようなパラメータをつかって最適化を行うケースは、実世界での意思決定ではあまり考えられません。それに対して、不確実性を考慮しながら最適化を行うという考えが生まれました。最もナイーブなやり方は、その不確実なパラメータを確率変数と見立ててその期待値を取って演算をすることです。しかし、実際に取る値は平均と大きく離れる場合があります(Savage, Scholtes and Zweidler 2006, Savage 2012)。平均値から大きく離れることを避けるために、以下のような**確率的計画法**が導入されました。\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\inf _{x \\in \\mathcal{X}} \\mathbb{E}_{\\mathbb{P}}[\\ell(x, Z)] \\tag{1.1}\n",
    "\\end{equation*}\n",
    "$$\n",
    "これは、不確実なパラメータの期待値を直接取るのではなく、$\\ell$に対して期待値を取ります。$\\ell$は確率変数を入力とする関数ですが、確率変数とみなすことができます。これはいい感じの定式化なのですが、**確率分布が既知**であるという仮定が必要です。さらに、この定式化は期待値があるためすべての要素を足す必要があり、次元の呪いを受けます。そこで以下のように新しい定式化を考えます。\n",
    "$$\n",
    "\\inf _{x \\in \\mathcal{X}} \\sup _{z \\in \\mathcal{Z}} \\ell(x, z)\n",
    "$$\n",
    "この定式化を、**ロバスト最適化問題**といいます。例えば、$\\ell$が状態価値関数であれば、ロバストMDPにおける最適化問題と考えるができます。しかし、ロバスト最適化は、目的関数の実現値を直接的に考慮して最適化をするため、過度に保守的になる場合があります。それに対して、目的関数の期待値に対してロバスト最適化問題を解く方法を**分布ロバスト最適化**問題といいます。\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\inf _{x \\in \\mathcal{X}} \\sup _{\\mathbb{P} \\in \\mathcal{P}} \\mathbb{E}_{\\mathbb{P}}[\\ell(x, Z)] \\tag{1.2}\n",
    "\\end{equation*}\n",
    "$$\n",
    "## 分布ロバストの歴史\n",
    "**TODO**\n",
    "\n",
    "## 不確実性集合\n",
    "ロバストMDPで主に使われる不確実性集合はKL集合や$L_2$ノルムの集合などが挙げられます。ここでは、より一般化された分布ロバスト最適化という枠組みで、不確実性集合をまとめていこうと思います。\n",
    "\n",
    "初期のDROに関する研究では、**モーメント不確実性集合**が用いられていました。モーメントとは、確率分布における平均や分散など、分布の特徴を示すものです。モーメント不確実性集合は、分布が大きく異なるようなものでも同じ集合に含まれてしまうという問題がありました。例えば平均が0という制約を考えると、ガウス分布や、一様分布がふくまれてしまいます。これではそもそも最適化問題を解くことが困難になってしまいます。そこで、近年(2013～)の研究では、確率分布(履歴データから推定した経験平均)そのものの距離(のようなもの)を制約として考える **$\\phi$(ファイ)-ダイバージェンス**や**Wasserstein 距離**を用いた不確実性集合を導入しました。さらに最近(2018～)は、**最適輸送における距離**(のようなもの)を用いて不確実性集合を導入するケースが増えています。\n",
    "\n",
    "### モーメント不確実性集合\n",
    "#### 変数定義\n",
    "*   **$\\mathbb{E}_{\\mathbb{P}}[f(Z)]$**：確率分布 $\\mathbb{P}$ に関するモーメント関数 $f$ の期待値を表す。\n",
    "*   **$\\mathcal{F}$**：モーメント不確実性集合。モーメントの可能な値の範囲を定める。\n",
    "*   **$\\mathcal{Z}$**：確率変数 $Z$ の取りうる値の集合\n",
    "\n",
    "#### 一般化された形\n",
    "$f: \\mathcal{Z} \\rightarrow \\mathbb{R}^{m}$ はボレル可測なモーメント母関数とします。$\\mathcal{F} \\subseteq \\mathbb{R}^{m}$ は不確実性集合とします。一般化されたモーメント不確実性集合は、モーメントの期待値が不確実性集合に属するような、確率分布の集合です。\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\mathcal{P}=\\left\\{\\mathbb{P} \\in \\mathcal{P}(\\mathcal{Z}): \\mathbb{E}_{\\mathbb{P}}[f(Z)] \\in \\mathcal{F}\\right\\} \n",
    "\\end{equation*}\n",
    "$$\n",
    "この形式は、チェビシェフの不等式に関する研究から生まれたものです。この定式化を用いて、具体的な例を見てみましょう\n",
    "\n",
    "#### 具体例①：サポートのみの不確実性集合\n",
    "不確実性集合の制約条件として、サポートであるかどうかを考えます。サポートであるかどうか、は確率分布が確率0でないものを取りうるかどうかで判断します。ですので、最もプリミティブな制約を持つ不確実性集合といえるかもしれません。\n",
    "\n",
    "具体的に見ていきましょう。\n",
    "サポートのみの不確実性集合は、一般化された形の$f(z)=1$ と $\\mathcal{F}=\\{1\\}$ のケースです。定式化すると、\n",
    "$$\n",
    "\\mathcal{P}=\\left\\{\\mathbb{P} \\in \\mathcal{P}(\\mathcal{Z}) \\mid \\mathbb{E}_{\\mathbb{P}}[1]=1\\right\\}\n",
    "$$\n",
    "ここで、\n",
    "$$\n",
    "\\mathbb{E}_{\\mathbb{P}}[1]=\\int_{\\mathcal{Z}} 1 \\cdot d \\mathbb{P}(z)=\\mathbb{P}(\\mathcal{Z})=1\n",
    "$$\n",
    "これは、全確率が1かどうかの制約です。これは実質的に不確実性集合に属する確率分布が1つになるため、ミニマックスの内側最小化は、不確実性集合に属する確率変数に対してではなく、ある確率分布に対する確率変数を用いたものになります。つまり、分布ロバスト最適化というよりは、従来のロバスト最適化と同義となります。\n",
    "$$\n",
    "\\inf _{x \\in \\mathcal{X}} \\sup _{\\mathbb{P} \\in \\mathcal{P}(\\mathcal{Z})} \\mathbb{E}_{\\mathbb{P}}[\\ell(x, Z)]=\\inf _{x \\in \\mathcal{X}} \\sup _{z \\in \\mathcal{Z}} \\ell(x, z)\n",
    "$$\n",
    "#### 具体例②：マルコフ不確実性集合\n",
    "マルコフの不等式を思い出しましょう。これは、確率変数の実現値が、ある値$\\tau>0$よりも大きくなる確率の上界を、確率分布の真の平均$\\mu$と$\\tau$で表したものです。マルコフの不等式で評価できる分布は、「平均はわかっているけど、それ以外の情報が分からない(わかってても良い)分布」です。マルコフ不確実性集合は、その評価できる分布を要素としています。つまり、$Z$の期待値が$\\mu$になるような確率分布を要素とした集合です。平均のみに制約を与えているため、形状や分散、その他モーメントが大きく異なるような分布も要素として受け入れることがあり、これは最適化を困難にさせる可能性があります。\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\mathcal{P}=\\left\\{\\mathbb{P} \\in \\mathcal{P}(\\mathcal{Z}): \\mathbb{E}_{\\mathbb{P}}[Z]=\\mu\\right\\} \n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "#### 具体例③：チェビシェフ不確実性集合\n",
    "チェビシェフの不等式は分散も分かっていて小さい場合、よりタイトな上界をだすことができています。それから転じて、以下のように分散の制約を追加したチェビシェフ不確実性集合を定義します。\n",
    "\n",
    "$\\mathcal{P}=\\left\\{\\mathbb{P} \\in \\mathcal{P}(\\mathbb{R}): \\mathbb{E}_{\\mathbb{P}}[Z]=\\mu, \\mathbb{E}_{\\mathbb{P}}\\left[Z^{2}\\right]=\\sigma^{2}+\\mu^{2}\\right\\}$ \n",
    "\n",
    "#### 具体例④：モーメントが不確実な場合のチェビシェフ不確実集合\n",
    "平均や分散が完全にわからず、推定誤差がある場合に用いられることがあります。\n",
    "\n",
    "#### 具体例⑤平均分散不確実集合\n",
    "平均は既知と仮定し、制約を与えて、分散に関する制約を工夫します。後者がチェビシェフ不確実性集合との違いです。\n",
    "\n",
    "#### 具体例⑥高次モーメント不確実集合\n",
    "尖度をはじめとした、高次モーメントに対して制約を与えた不確実性集合です。分布の様々な性質まで制約として制御できますが、一般的にはこの不確実性集合を用いた最適化問題は**NP困難**になります。また、計算コストが非常に高くなるため、近似解法を使って解くことが前提となることが多いです。\n",
    "\n",
    "### $\\phi$-ダイバージェンス不確実性集合\n",
    "#### 定義\n",
    "*   **$\\phi$**：エントロピー関数\n",
    "*   **$\\phi^{\\infty}(1)$**：$\\phi$ のリセッション関数\n",
    "*   **$\\mathrm{D}_{\\phi}(\\mathbb{P}, \\hat{\\mathbb{P}})$**：$\\phi$-ダイバージェンス\n",
    "*   **$\\operatorname{KL}(\\mathbb{P}, \\hat{\\mathbb{P}})$**：KLダイバージェンス\n",
    "*   **$\\mathrm{TV}(\\mathbb{P}, \\hat{\\mathbb{P}})$**：全変動距離\n",
    "*   **$\\chi^{2}(\\mathbb{P}, \\hat{\\mathbb{P}})$**：$\\chi^2$-ダイバージェンス\n",
    "*   **$\\mathbb{P} \\ll \\hat{\\mathbb{P}}$**：$\\mathbb{P}$ が $\\hat{\\mathbb{P}}$ に関して絶対連続\n",
    "*   **$\\mathcal{F}$**：すべての有界ボレル関数 $f: \\mathcal{Z} \\rightarrow \\operatorname{dom}\\left(\\phi^{*}\\right)$ の族\n",
    "\n",
    "\n",
    "### 最適輸送不確実性集合\n",
    "\n",
    "#### Wasserstein不確実性集合\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
